---
title: 'The Local Revolution'
description: 'A guide to understanding AI'
icon: "ðŸ¦†"
pubDate: '2025-08-07'
heroImage: "/src/assets/local-revolution.jpeg"
tags: [ 'AI', 'language models', 'Python', 'GitHub', 'Local models', 'CrewAI', 'Perplexity', 'ElevenReader']
---

# The Local Revolution

![option paralysis](src/assets/local-revolution.jpeg)
You're drowning in AI hype, aren't you? Every day brings another "revolutionary" tool, another expert claiming everything will change, another decision about whether to pay for tokens or risk your privacy. Meanwhile, you're probably still trying to figure out if any of this actually matters for **YOUR** work.

I spent months bouncing between expensive cloud services and janky local setups, watching my credit card balance fluctuate with my curiosity. The breaking point came when I realized I was making decisions about AI tools with the vocabulary of a tourist-knowing just enough to be dangerous, not enough to be strategic.

![disappointed at llama](src/assets/oh-llama.jpeg)

My pain with language models has been the constant trade-off between intelligence and speed. Especially with tool calls-if a model doesn't search the internet properly or fumbles basic function calls, it's not nearly as valuable as the marketing promises. I would gladly give up some of the raw intelligence for better tool calling. But how do you even evaluate that trade-off when you're not sure what you're looking at?

Then something shifted. OpenAI's GPT-OSS-20B now runs on my 4-year-old MacBook Pro with relative ease and at a palatable pace with good results. But this is 100% private. I've seen people have these models run their MacBooks for them-a hazardous task, but an impressive one nonetheless. What do we do now?

Here's what I learned the hard way: **WITHOUT A FUNDAMENTAL VOCABULARY, YOU'RE NOT MAKING INFORMED DECISIONS ABOUT AI-YOU'RE JUST REACTING TO MARKETING.** The difference between understanding these tools and being manipulated by them comes down to speaking their language.

![reading carefully](src/assets/Reading-carefully.jpeg)

Learn. Prioritize learning some programming. People will tell you that vibe-coding has commoditized programming, and that's true. Remembering SYNTAX is, but the understanding of the underlying structures, architectures, and patterns is much less so. Even professional "vibe coders" with years of experience struggle to tame language models to do the work they expect.

Your value lies in your understanding of a specific field and applying intelligence to it. Here's the catch: now YOU can have intelligence in a laptop. You can learn to fine-tune it, make it do things for you, or create your own personal workflows with tools like CrewAI or just plain regular Python. But you have to have a certain vocabulary and a certain bar of understanding.

You feeling overwhelmed about all the AI hype and nonsense, both in the industry and in society in general, will not make it less real. If nothing else, someone WILL try to sell you or your loved ones AI companions that can run on your laptop with no guardrails whatsoever. Which we already know can be deeply addictive and harmful in some cases.

OK, let's pause the doom and gloom for now.

![the local revolution](src/assets/dictionary.jpeg)

My solution? Start speaking AI's native language, one word at a time. This isn't academic-it's survival vocabulary for staying relevant. Here's your daily practice routine that takes less time than your morning coffee.

First, find a text-to-speech tool, whatever you find the easiest. I've been using **ElevenReader** for longer papers and **Perplexity** for searches and articles. Yes, Perplexity can do the research and read it to you however you see fit for a few dollars. Obviously, don't start with raw academic papers if you feel it's too advanced.

I'll give you a vocabulary. Take one word a day and explore however you want, whatever you have time for. 5-10 minutes is more than enough. Go do the dishes and open **Perplexity**.

### Tier 1: Basic

- **Data:** As a ((role)) in the ((industry)), explain the fundamental role of **data** in AI. What kind of data is most impactful?
- **Large Language Model (LLM):** I'm a ((role)) in the ((industry)). Explain what a **Large Language Model (LLM)** is in practical terms I can apply to my work.
- **Prompts & Tokens:** For a ((role)) in the ((industry)), explain the direct relationship between **prompts** and **tokens**. How does this correlation affect cost and output quality?
- **Image Generation Model:** As a ((role)) in the ((industry)), give me a concise, high-level explanation of an **image generation model**.
- **AI Learning:** Explain how AI models **learn**, using an analogy relevant to a ((role)) in the ((industry)).
- **Neural Network:** Break down what a **Neural Network** is for a ((role)) in the ((industry)). Focus on the conceptual model, not the deep mathematics.

### Tier 2: Intermediate

- **Transformer Model:** As a ((role)) in the ((industry)), explain why the **Transformer architecture** is a critical innovation for modern AI.
- **Generative AI:** I'm a ((role)) in the ((industry)). Explain **Generative AI** and provide three practical applications or disruptions relevant to my field.
- **LoRA:** For a ((role)) in the ((industry)) looking to create custom styles, explain the function of a **LoRA** in image generation and when to use it.
- **Fine-tuning:** Explain **fine-tuning** for language models. As a ((role)) in the ((industry)), what is a realistic scenario where I would choose fine-tuning over advanced prompt engineering?

### Tier 3: Advanced

- **Agentic AI:** As a ((role)) in the ((industry)), explain **Agentic AI**. How does it fundamentally differ from current generative models, and what new capabilities does it unlock?
- **Reinforcement Learning:** Explain **Reinforcement Learning** (specifically RLHF) in the context of LLMs. How does it make a model more aligned and useful for a ((role)) in the ((industry))?
- **Diffusion Model:** For a ((role)) in the ((industry)), provide a conceptual, non-mathematical explanation of how a **Diffusion Model** generates an image from noise.
- **Alignment:** Explain **AI Alignment** for a ((role)) in the ((industry)). Why is it a critical problem, and what are the practical consequences of a misaligned model?
- **Emergent Capability:** I'm a ((role)) in the ((industry)). Explain what **emergent capabilities** are in LLMs. Are they predictable, and what are the implications for future development?

**The Necessary Pain:** Don't mistake surface knowledge for understanding. I've seen too many people memorize definitions and think they're ready to architect AI solutions. This vocabulary is your foundation, not your destination. The real learning happens when you start breaking things.

This will give you a basic vocabulary and provide a base to have informed opinions about artificial intelligence, rather than just conform to hearsay and hype. We failed to understand the internet, social media, and gaming until after they reshaped society. AI won't wait for us to catch up. The question isn't whether these tools will impact your field-it's whether you'll understand them well enough to use them strategically rather than stumble through them reactively. 

People are already suffering from "AI-induced option-paralysis" and end up in precarious situations that put their privacy and professional experience at risk because they don't understand the implications.

Start with one word today. Your future self will thank you when everyone else is still googling in 2026.

*NEXT:* An introduction to LM Studio and have private chats with your data and locally hosted MCPs.